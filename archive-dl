#!/bin/bash

# TODO: 
# - be able to use comments in url file

# - remove completed downloads from the url,
#   helps when restarting downloads.

# - loading stuff to menu is slow, can it be faster

# - Tidy up menu entries
# - Better way of detecting invalid urls in update_list()

# - option to choose what to do with the archive, either to play (media file) or etc.

# - Help Menu (Very Low Prioraty)

# TODO: add caching layer for every function that has expensive loops

# TODO: Things to be decide
# - make the script to be able to go into folder in archives
# - convert to different language

# TODO: Archive Groups are lost when updating the archive. 
# - Make The Group Stick between updates.

# Be able to Process torrent files

# TODO: Be compatible with termux (unrooted)
# - path need to be fixed [?]
# - fail on the first sign of errors that would be a major problem

set -o pipefail

# TODO check also if notify-send is installed
notify_msg(){ notify-send "$1" "$2"; }
print_msg(){ printf "%s\n" "$1" 2>/dev/null; }
print_exit(){ print_msg "$1" && exit 1; }

init_prg_vars()
{
    # Directories and File Constants 
    if [ -n "$XDG_CONFIG_HOME" ]; then
        PRG_DIR="$XDG_CONFIG_HOME/ArchiveDownloader"
    else
        PRG_DIR="$HOME/.config/ArchiveDownloader"
    fi

    ARCHV_CSV_DIR="$PRG_DIR/ArchiveData"

    DWNLD_DIR="$PRG_DIR/Downloads"
    INCMPLT_DWNLD_DIR="$DWNLD_DIR/.incomplete"

    ARCHV_CSV_DIR="$PRG_DIR/ArchiveData"
    ARCHV_URL_FILE="$PRG_DIR/archive.urls"

    DWNLD_DIR_NAME="DWNLD-$(date '+%F@%H:%M:%S')"
    DWNLD_URL_NAME="DWNLD-$(date '+%F@%H:%M:%S').urls"

    CUR_DWNLD_DIR="$DWNLD_DIR/$DWNLD_DIR_NAME"
    GROUP_CACHE="$PRG_DIR/.group_cache"

    # Global Lists
    SEL_ARCHV=()
    SEL_FILES=()
    QUERY_RESULT=()
    mapfile -d $'\0' DATABASE < \
        <(find "$ARCHV_CSV_DIR" -name "*.csv" -type f -print0)

    # aria2c settings
    DRY_RUN="false"
    MAX_RETRIES="0"
    CONCURRENT_DWNLD="1"

    # Create the directories if they doesn't exists
    if [ ! -d "$PRG_DIR" ]; then 
        mkdir -p "$PRG_DIR" || print_exit "Path "$PRG_DIR" cannot be created"
    fi

    [ ! -f "$GROUP_CACHE" ] && touch "$GROUP_CACHE"
    [ ! -d "$DWNLD_DIR" ] && mkdir -p "$DWNLD_DIR"
    [ ! -d "$ARCHV_CSV_DIR" ] && mkdir -p "$ARCHV_CSV_DIR"
    [ ! -d "$INCMPLT_DWNLD_DIR" ] && mkdir -p "$INCMPLT_DWNLD_DIR"

    return 0
}

# read from an archive ".csv" file, return metadata
get_csv_data()
{
    arg="$1"
    csv="$2"

    [ ! -f "$csv" ] && print_exit "file named $csv not found"
    case ${arg} in
        name) 
            val="$( tail -n 1 "$csv" | awk -F "," '{print $1}' )"
            [ -z "$val" ] && val="$(basename "${csv%%.csv}")"
            ;;
        url) val="$( tail -n 1 "$csv" | awk -F "," '{print $2}' )";;
        date) val="$( tail -n 1 "$csv" | awk -F "," '{print $3}' )";;
        group) val="$( tail -n 1 "$csv" | awk -F "," '{print $4}' )";;
        group_index) val="$( tail -n 1 "$csv" | awk -F "," '{print $5}' )";;
        *) print_exit "unknown argument $arg"
    esac

    echo "$val"
}

update_csv_data()
{
    tag="$1"
    val=$2
    csv="$3"

    [ ! -f "$csv" ] && print_exit "file named $csv not found"

    # get the old data
    name="$(get_csv_data "name" "$csv")"
    url="$(get_csv_data "url" "$csv")"
    date="$(get_csv_data "date" "$csv")"
    group="$(get_csv_data "group" "$csv")"
    group_index="$(get_csv_data "group_index" "$csv")"

    # set the new data
    case ${tag} in
        name)name=$val;;
        url)url=$val;;
        date)date=$val;;
        group)group=$val;;
        group_index)group_index=$val;;
        *) print_exit "unknown target $tag"
    esac

    file_content="$(cat "$csv")"

    # old data line to be changed
    old_data="$(tail -n 1 "$csv")"
    # format the new data
    new_data="$name,$url,$date,$group,$group_index,NULL"

    # overwrite the old file
    echo "${file_content/$old_data/$new_data}" > "$csv"
}

yesno_prompt()
{
    msg="$1"
    prompt="$(dialog --yesno --stdout "$msg" 0 0)"
    stat="$?"

    [ stat -gt 0 ] && return 1

    return 0
}

inputbox_menu()
{
    question="$1"
    default_val="$2"
    answ="$(dialog --inputbox --stdout "$question" 0 0 "$default_val")"
    stat="$?"

    [ $stat -gt 0 ] && return 1
    echo "$answ"

}

edit_archv_name()
{
    while (true); do
        # Files to choose
        opts=()
        for csv in "${DATABASE[@]}"; do
            name="$(get_csv_data "name" "$csv")"
            opts+=("$csv")
            opts+=("$name")
        done
        
        # Select a file
        sel_csv="$(dialog --no-tags --menu --stdout "what to change" 0 0 0 "${opts[@]}")"
        sel_csv_stat="$?"

        [ "$sel_csv_stat" -gt 0 ] && break
        [ -z "$sel_csv" ] && continue
        
        # get the old name, and get the user input for the new one
        old_name="$(get_csv_data "name" "$sel_csv" )"
        new_name="$(inputbox_menu "Rename the Archive" "$old_name")"
        
        # in case the user didn't enter anything
        [ -z "$new_name" ] && new_name="$old_name"
        
        # change the name
        update_csv_data "name" "$new_name" "$sel_csv"
    done
}

# TODO: Need to also edit archive.url
# edit_archv_url()
# {
#
# }

edit_archv_group()
{
    opts=()

    while (true); do

        # Generate Options
        for csv in "${DATABASE[@]}"; do
            name="$(get_csv_data "name" "$csv")"
            group="$(get_csv_data "group" "$csv")"
            index="$(get_csv_data "group_index" "$csv")"

            [ -z "$group" ] && update_csv_data "group" "NULL" "$csv"
            [ -z "$index" ] && update_csv_data "group_index" "1" "$csv"

            opts+=("$csv")
            opts+=("[$group: $group_index] $name")
            opts+=("OFF")
        done

        [ -z "${opts[*]}" ] && continue

        # choose the file
        sel_archv=("$(dialog --title " Select Archives to be Grouped " --no-tags --reorder \
            --buildlist --stdout "Notice: Order of Selection Matters!" 0 0 0 "${opts[@]}")")
        sel_archv_stat="$?"
        [ "$sel_archv_stat" -gt 0 ] && break
        [ -z "${sel_archv[*]}" ] && continue

        [ -f "$GROUP_CACHE" ] && rm -f "$GROUP_CACHE"
        
        # enter the group name
        group_name="$(inputbox_menu "Name of the Group" "")"
        group_name_stat="$?"
        [ "$group_name_stat" -gt 0 ] && break
        [ -z "$group_name" ] && continue
       
        # change the group names in each file
        count=0
        for sel_csv in ${sel_archv[@]}; do
            count="$((count + 1))"
            update_csv_data "group" "$group_name" "$sel_csv"
            update_csv_data "group_index" "$count" "$sel_csv"
        done
    done
}

edit_archv_menu()
{
    while (true); do
        opts=(0 "Edit Archives Names" 1 "Edit Url" 2 "Create Archive Groups")
        menu="$(dialog --title " Archive Editing Menu " --no-tags \
            --menu --stdout "Select an Option" 0 0 0 "${opts[@]}")"
        stat="$?"
        [ "$stat" -gt 0 ] && break
        case ${menu} in
            0) edit_archv_name;;
            1) edit_archv_url;;
            2) edit_archv_group;;
        esac
    done
}

# select archive data to access
sel_archive()
{
    opts=()
    group_list=()
    for csv in "${DATABASE[@]}"; do
        # skip if file has only 1 line
        [ "$(wc -l "$csv" | awk '{print $1}')" -eq 1 ] && continue

        # get the archive name 
        name="$(get_csv_data "name" "$csv")"

        # Groups
        group="$(get_csv_data "group" "$csv")"
        [ -z "$group" ] && group="NULL"

        if [ "$group" != "NULL" ]; then

            # skip groups that has been processed
            grep -q "$group" <<< "${group_list[*]}" && continue

            name="$group"

            # add to the list of processed groups
            group_list+=("$group")

            # read cache file if exist 
            if grep -q "$group" "$GROUP_CACHE"; then
                csv="$(grep "$group" "$GROUP_CACHE" | cut -d "," -f2)"
            elif ! grep -q "$group" "$GROUP_CACHE"; then
                group_csv=()
                group_csv_files=()
                count=0

                # look in entire database for archives 
                # that is in the same group
                for file in "${DATABASE[@]}"; do

                    [ "$(get_csv_data "group" "$file")" != "$name" ] && continue

                    # To make the csv appear in the correct order
                    index="$(get_csv_data "group_index" "$file")"

                    # exit if the csv file has no index
                    [ -z "$index" ] && print_exit "$file, has no group index"
                    
                    # store the files by index
                    declare -A group_csv+=(["$index"]="$file")
                    
                    # count the number of archives in the group
                    count=$((count + 1))
                done
                
                # append the csv file according to it's index
                for (( i=0; i<=count; i++ )); do
                    group_csv_files+=("${group_csv[$i]}")
                done

                csv="${group_csv_files[*]}"

                # write to cache file...
                echo "$name,$csv" >> "$GROUP_CACHE"
            fi

        fi

        opts+=("$csv")
        opts+=("$name")
        opts+=("OFF")
    done
    
    [ -z "${opts[*]}" ] && print_exit "cancelled..."

	SEL_ARCHV=("$(dialog --title " Archive Selection Menu " --reorder \
        --no-tags --separate-output --visit-items --buildlist \
        --stdout "Choose a Archive" 0 0 0 "${opts[@]}")")
    stat="$?"

    [ "$stat" -gt 0 ] && print_exit "cancelled..."
    [ -n "${SEL_ARCHV[*]}" ] && return 0
}

search_archv()
{
    in_search=1
    opts=()
    grep_result=""

    query="$(inputbox_menu "Look for what?" "")"

    [ -z "$query" ] && in_search=0

    if [ $in_search -eq 1 ]; then 

        for archv in ${SEL_ARCHV[@]}; do
            csv_data="$(head -n -1 "$archv")"
            
            if [ $in_search -eq 1 ] && grep -q "$query" <<< "$csv_data"; then
                    # re-set csv_data to be query result
                    grep_result="$(grep "$query" <<< "$csv_data")"

            # if grep returns nothing 
            elif [ $in_search -eq 1 ] && ! grep -q "$query" <<< "$csv_data"; then
                    continue
            fi

            [ -z "$grep_result" ] && break 

            archv_url="$(get_csv_data "url" "$archv")"
            while IFS=',' read -r file_url file_name upload_date file_size; do
                opt_stat="OFF"

                if [ -n "${SEL_FILES[*]}" ]; then
                    for sel_file in ${SEL_FILES[@]}; do
                        [ "$sel_file" == "$archv_url/$file_url" ] && opt_stat="ON"
                    done
                fi

                if [ -n "${QUERY_RESULT[*]}" ]; then
                    for search_result in ${QUERY_RESULT[@]}; do
                        [ "$search_result" == "$archv_url/$file_url" ] && opt_stat="ON"
                    done
                fi

                opts+=("$archv_url/$file_url")
                opts+=("- $file_name [$file_size] [$upload_date]") 
                opts+=("$opt_stat")
            done <<< "$grep_result"
        done

        if [ -n "${opts[*]}" ]; then

            search_result="$(dialog --title "Search Results" \
                --reorder --no-tags --separate-output --checklist \
                --stdout "Select Files to Download" 0 0 0 "${opts[@]}")"
            stat="$?"

            if [ "$stat" -eq 0 ] && [ -n "$search_result" ]; then
                QUERY_RESULT+=("$search_result")
            else
                dialog --title " Canceled " --msgbox "Canceling Search..." 0 0
            fi
        else
            dialog --title " Nothing Found! " \
                --msgbox "Nothing related to '$query' Found!" 0 0
        fi

    fi

    in_search=0
}

sel_files()
{
    search_files=0

    while (true); do

        archv_names=()
        opts=()
        csv_data=""

        for archv in ${SEL_ARCHV[@]}; do

            [ "$(wc -l "$archv" | awk '{print $1}' )" -lt 2 ] && continue

            csv_data="$(head -n -1 "$archv")"

            # get the archive name and url
            archv_names+=(" $(get_csv_data "name" "$archv") ")
            archv_url="$(get_csv_data "url" "$archv")"

            # get data from each line in the csv file
            # generate options for the dialog menu
            while IFS=',' read -r file_url file_name upload_date file_size; do
                # default state
                opt_stat="OFF"
                
                # re-select selected files after searches
                if [ -n "${SEL_FILES[*]}" ]; then
                    for sel_file in ${SEL_FILES[@]}; do
                        [ "$sel_file" == "$archv_url/$file_url" ] && opt_stat="ON"
                    done
                fi

                # Process search result
                if [ -n "${QUERY_RESULT[*]}" ]; then
                    for search_result in ${QUERY_RESULT[@]}; do
                        [ "$search_result" == "$archv_url/$file_url" ] && opt_stat="ON"
                    done
                fi

                # add them to the argument array
                opts+=("$archv_url/$file_url")
                opts+=("- $file_name [$file_size] [$upload_date]") 
                opts+=("$opt_stat")

            done <<< "$csv_data"
        done

        # reset to false
        [ $search_files ] && search_files=0

        [ -z "${opts[*]}" ] && print_exit "cancelled..."

        SEL_FILES=("$(dialog --title "${archv_names[*]}" --reorder --no-tags \
            --separate-output --extra-button --extra-label "Search" --visit-items \
            --buildlist --stdout "Choose Files to Download" 0 0 0 "${opts[@]}")")
        stat="$?"
        
        if [ "$stat" -eq 0 ]; then

            # exit if nothing if nothing is selected
            [ -z "${SEL_FILES[*]}" ] && print_exit "cancelled..."

            # otherwise, break out of the loop
            break

        # if "search" button is pressed
        elif [ "$stat" -eq 3 ]; then
            # begin search
            search_archv

            # if nothing is entered re-run the loop
            [ -z "$QUERY_RESULT" ] && continue
            
            # begin search
            search_files=1
        else
            print_exit "cancelled..."
        fi
    done

    [ -n "${SEL_FILES[*]}" ] && return 0
}

# set aria2c settings
download_settings_menu()
{
    while (true); do
        opts=(\
            0 "Max Retries ($MAX_RETRIES)" \
            1 "Concurrent Downloads ($CONCURRENT_DWNLD)" \
            2 "Dry Run ($DRY_RUN)"\
            3 "Change Download Directory"\
        )

        menu="$(dialog --title " Download Settings " \
            --extra-button --extra-label "Done" --ok-label "Edit" --reorder --no-tags \
            --menu --stdout "Select a Setting to Change" 0 0 0 "${opts[@]}")"
        stat="$?"

        [ "$stat" -eq 1 ] && print_exit "Canceled..."
        [ "$stat" -gt 0 ] && break

	    case ${menu} in

            0)  MAX_RETRIES="$(dialog --title " Maximum Retries Allowed " --ok-label "Done" \
                    --rangebox --stdout "Notice: 0 Means Unlimited" 0 0 0 100 "$MAX_RETRIES")"
            ;;

            1)  CONCURRENT_DWNLD="$(dialog --title " Number of Concurrent Downloads " --ok-label "Done" \
                    --rangebox --stdout "Number of Files Downloaded at a Time" 0 0 1 100 "$CONCURRENT_DWNLD")"
            ;;

            2)  dialog --title " Dry Run: ($DRY_RUN) " \
                    --yesno "Don't Download Anything, Just Check if the File Exists [Y/n]" 0 0 
                answ="$?"
                [ "$answ" -eq 0 ] && DRY_RUN="true" || DRY_RUN="false"
            ;;

            # TODO: add option to select via file manager/similar
            3)  while(true); do
                    user_dwnld_dir="$(inputbox_menu "Enter the Download Path: " "$CUR_DWNLD_DIR")"
                    user_dwnld_dir_stat="$?"
                    [ "$user_dwnld_dir_stat" -gt 0 ] && break
                    CUR_DWNLD_DIR="$user_dwnld_dir" && break
                done
            ;;

        esac
    done
}

# Download the files
download_files()
{
    sel_archive || print_exit "error(s) occured when processing selected archive..."
    sel_files || print_exit "error(s) occured when processing selected files..."

    # confirm download
	dialog --title " Continue to Download? " \
        --yesno "Files to Download: $(printf "%s\n" "${SEL_FILES[@]}" | wc -l)" 0 0
	answ="$?"

	[ "$answ" -ne 0 ] && print_exit "cancelled..."

    download_settings_menu

    # create the download directory for the files
    [ ! -d "$CUR_DWNLD_DIR" ] && mkdir -p "$CUR_DWNLD_DIR"

    # Write the selected file's Url to a file
    printf "%s\n" "${SEL_FILES[@]}" >> "$CUR_DWNLD_DIR/$DWNLD_URL_NAME"

    # begin the download
    clear

    aria2c --dry-run "$DRY_RUN" -m "$MAX_RETRIES" -j "$CONCURRENT_DWNLD" \
        -d "$CUR_DWNLD_DIR" -i "$CUR_DWNLD_DIR/$DWNLD_URL_NAME"
    dwnld_stat="$?"

    case ${dwnld_stat} in
        0) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Ended Successfully..." ;;
        1) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Ended With an Unknown Error..." ;;
        2) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Timed Out!" ;;
        3) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Resources Not Found!" ;;
        4) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Resources Not Found!" ;;
        5) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Aborted, speed too slow..." ;;
        6) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Ended With a Network Problem..." ;;
        7) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Ended With Partially Downloaded Files" ;;
        9) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Aborted, Not Enough Space Left..." ;;
        11) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Aborted, Another instance is Downloading the Same File" ;;
        13) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Aborted, Already Exists!" ;;
        19) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Aborted, Name Resolution Failed..." ;;
        23) dwnld_result_msg="Download '$CUR_DWNLD_DIR' Aborted, Too Many Redirects!" ;;
    esac

    # Delete auto-generated files if dry run is selected
    print_msg "$dwnld_result_msg" && notify-send "Archive.org Downloader" "$dwnld_result_msg" 2>/dev/null

    if [ "$DRY_RUN" == "true" ]; then
        rm -rf "$CUR_DWNLD_DIR"
    else
        if [ "$dwnld_stat" -gt 0 ]; then
            # if any error occured move the download directory to 
            # the incomplete downloads directory
            mv "$CUR_DWNLD_DIR" "$INCMPLT_DWNLD_DIR"
            print_exit "Moved incomplete downloads to $INCMPLT_DWNLD_DIR"
        fi
    fi
}

update_list()
{
    [ ! -f "$ARCHV_URL_FILE" ] && print_exit "Error: archive.url not found!"

	dialog --yesno "Update Existing Files?" 0 0
	answ="$?"

    print_msg "Updating Database..."

    a_count=0
    f_count=0

	while IFS=" " read -r url name ; do

        ! grep -q "https://archive.org/download/" <<< "$url" && continue

		csv_name="$(cut -d "/" -f5 <<< "$url").csv"

        if [ "$answ" -ne 0 ]; then
            # don't update if the csv already existed
            [ -f "$ARCHV_CSV_DIR/$csv_name" ] && continue
        fi

        # skip empty lines
        [ -z "$url" ] && continue

        a_count=$((a_count + 1))

        # get the url html
		print_msg "#### Fetching data from '$url'..." 
		fetch_list="$(curl --silent --fail "$url")"
		stat="$?"

		if [ "$stat" -gt 0 ]; then
			print_msg "WARNING: An error occured when downloading $url, exited with error code $stat"
            f_count=$((f_count + 1))
            continue
        fi

        # Convert html to csv
		print_msg "> Generating csv from $url"
		tr -d '\n' <<< "$fetch_list" | \
            grep -E -o '<tbody>.*</tbody>' | \
			sed -r 's/<td><a href=//g' | \
            sed -r 's/<\/tr>/\n/g; s/  //g' | \
			sed -r 's/<(\/td|\/a|tr.)>//g; s/\(<a.*\)//g; s/,/_/g' | \
			sed -r 's/<td>/,/g; s/">/,/g; s/ ,/,/g' | \
			tr -d '"' | head -n -1 | tail -n +2 > "$ARCHV_CSV_DIR/$csv_name"
		stat="$?"

		if [ "$stat" -eq 0 ]; then
            # append to the last line the metadata, name of archive, url, and last modified.
            echo "$name,$url,$(date +'%d-%b-%Y %H:%M'),NULL,NULL,NULL," >> "$ARCHV_CSV_DIR/$csv_name"
			print_msg "> Success... Generated $ARCHV_CSV_DIR/$csv_name"
		else
			print_msg "> Error: Failed to generate csv from $url"
            f_count=$((f_count + 1))
		fi

	done <<< "$(cat "$ARCHV_URL_FILE")"

    print_msg "Process completed, $f_count Failed, out of $a_count"
}

continue_downloads()
{
    clear
    mapfile -d $'\0' incmplt_dwnlds < \
        <(find "$INCMPLT_DWNLD_DIR" -maxdepth 1 -mindepth 1 -type d -print0)

    [ -z "${incmplt_dwnlds[*]}" ] && print_exit "Nothing to Download"
    
    opts=()
    for dwnlds in "${incmplt_dwnlds[@]}"; do
        dwnld="$(basename $dwnlds)"
        opts+=()
        opts+=()
    done

    # select incomplete downloads
    # download_settings
    # dialog to edit url file
    # begin download
    # move to download dir if Successful
    # print exit if not
}

main(){
    init_prg_vars || print_exit "error(s) occured, exiting..."
	opts=( 1 "Download Files" 2 "Update Lists" 3 "Continue Downloads" 4 "Edit Archives")
	main_menu="$(dialog --title " Archive.org Downloader " --reorder --no-tags \
		--menu --stdout "What to do?" 0 0 0 "${opts[@]}")"
	case ${main_menu} in
		1) download_files ;;
		2) update_list;;
		3) continue_downloads ;;
        4) edit_archv_menu;;
	esac
}

main
